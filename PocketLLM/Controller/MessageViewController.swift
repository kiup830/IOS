//
//  MessageViewController.swift
//  PocketLLM
//
//  Created by ë¬¸ì¬í˜„ on 2025/06/14.
//


import UIKit

class MessageViewController: UIViewController {
    
    var currentConversation: Conversation?
    
    @IBOutlet weak var backButton: UIButton!
    
    @IBOutlet weak var messageStack: UIStackView!
    
    @IBOutlet weak var recordingButton: UIButton!
    
    @IBOutlet weak var recordingLabel: UILabel!
    
    var isRecording = false
    let mic_recodring = UIImage(named:"mic_recording")
    let mic_idle = UIImage(named:"mic_idle")
    
    var latestAudioFileURL: URL?
    
    
    // Servicesí´ë”ì˜ AudioRecorderService.swiftë‚´ í•¨ìˆ˜
    let recordService = AudioRecorderService()
    
    
    override func viewDidLoad() {
        super.viewDidLoad()
        
        if currentConversation == nil {
            startNewConversation()
        } else {
            loadExistingConversation()
        }
    }
    
    
    
    override func viewWillDisappear(_ animated: Bool) {
        super.viewWillDisappear(animated)
        
        navigationItem.hidesBackButton = true
        
        CoreDataManager.shared.saveContext()
    }
    
    
    func loadExistingConversation() {
        guard let conversation = currentConversation,
              let messages = conversation.messages as? Set<MiniConversation> else {return}

        let sortedMessages = messages.sorted {
            guard let date0 = $0.timestamp, let date1 = $1.timestamp else { return false }
            return date0 < date1
        }

        for msg in sortedMessages {
            let userLabel = createMessageLabel(text: msg.userText ?? "ë‚´ìš© ì—†ìŒ", isUser: true)
            let aiLabel = createMessageLabel(text: msg.aiText ?? "ë‚´ìš©ì—†ìŒ", isUser: false)
            messageStack.addArrangedSubview(userLabel)
            messageStack.addArrangedSubview(aiLabel)
        }
    }
    
    func startNewConversation() {
        let context = CoreDataManager.shared.viewContext

        let newConv = Conversation(context: context)
        newConv.id = UUID()
        newConv.createdAt = Date()
        
        let formatter = DateFormatter()
        formatter.locale = Locale(identifier: "ko_KR")
        formatter.dateFormat = "Mì›” dì¼ a h:mm"
        
        let dateString = formatter.string(from: Date())
        newConv.title = "ëŒ€í™” \(dateString)"

        try? context.save()
        self.currentConversation = newConv
    }
    
    
    func saveAndDisplayMiniConversation(userText: String, aiText: String) {
        guard let conversation = currentConversation else { return }
        let context = CoreDataManager.shared.viewContext

        let mini = MiniConversation(context: context)
        mini.id = UUID()
        mini.userText = userText
        mini.aiText = aiText
        mini.timestamp = Date()
        mini.conversation = conversation

        try? context.save()

        // âœ… UIStackViewì— ì¶”ê°€
        let userLabel = createMessageLabel(text: userText, isUser: true)
        let aiLabel = createMessageLabel(text: aiText, isUser: false)

        messageStack.addArrangedSubview(userLabel)
        messageStack.addArrangedSubview(aiLabel)
    }
    
    func createMessageLabel(text: String, isUser: Bool) -> UILabel {
        let label = PaddingLabel()
        label.text = text
        label.numberOfLines = 0
        label.textAlignment = isUser ? .right : .left
        label.textColor = .white
        label.backgroundColor = isUser ? .systemBlue : .darkGray
        label.layer.cornerRadius = 12
        label.layer.masksToBounds = true
        label.font = UIFont.systemFont(ofSize: 16)
        return label
    }

    
    @IBAction func backButtonTapped(_ sender: UIButton) {
        CoreDataManager.shared.saveContext()

        // ëŒ€í™” ì €ì¥ í›„ì´ì „ í™”ë©´ìœ¼ë¡œ ë˜ëŒì•„ê°€ê¸°
        navigationController?.popViewController(animated: true)
    }


    
    @IBAction func click_recording(_ sender: Any) {
        
        guard let button = sender as? UIButton else {return}
        
        isRecording.toggle()
        
        let imageName = isRecording ? "mic_recording" : "mic_idle"
        recordingLabel.text = isRecording ? "ğŸ”´ ë…¹ìŒ ì¤‘..." : "ìŒì„±ì„ ì…ë ¥í•˜ì„¸ìš”"
        
        if isRecording {
            BlinkEffect.start(on: recordingLabel)
            
            // recording function starts..
            latestAudioFileURL = recordService.startRecording()
            
            
            
        } else {
            BlinkEffect.stop(on: recordingLabel)
            
            // recording function stops..
            recordService.stopRecording()
            
            // ë…¹ìŒëœ ì˜¤ë””ì˜¤ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì—¬ Textë¡œ ë³€í™˜(OpenAI-Whisper)
            guard let audioURL = latestAudioFileURL else {
                        print("âŒ ë…¹ìŒ íŒŒì¼ URL ì—†ìŒ")
                        return
                    }

            print("ë…¹ìŒëœ íŒŒì¼ ê²½ë¡œ: \(audioURL.path)")

            STTService.shared.transcribeAudio(at: audioURL) { text in
                DispatchQueue.main.async {
                    guard let inputText = text else {
                                        print("âŒ STT ë³€í™˜ ì‹¤íŒ¨")
                                        return
                                    }
                    
                    print("STT í…ìŠ¤íŠ¸: \(inputText)")
                    
                    LLMService.shared.runLLM(with: inputText) { response in
                
                        DispatchQueue.main.async {
                            
                            print(" GPT ì‘ë‹µ: \(response)")
                            
                            // ì´í›„ UIstackviewì— ì‘ë‹µ ì¶”ê°€
                            self.saveAndDisplayMiniConversation(userText: inputText, aiText: response)
                        }
                        
                    }
                    
                }
            }
            
            
        }
        
        button.setImage(UIImage(named: imageName), for: .normal)
                
        
        
    }
    
    
    
}
 
